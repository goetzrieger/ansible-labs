= Lab: Ansible Tower for Advanced Users
:scrollbar:
:data-uri:
:toc: left
:numbered:
:icons: font
:imagesdir: ./images
:linkattrs:

// image::forum.jpg[]

== About this Lab

You have already used Ansible Automation quite a bit and have started to look into Tower? Or you are already using Tower? Cool. We prepared this lab to give a hands-on introduction to some of the more advanced features of Tower. You'll learn about:

* Using commandline tools to manage Ansible Tower
* Ansible Tower clustering
* Working with Instance Groups
* Using isolated nodes to manage remote locations
* Ways to provide inventories (importing inventory, dynamic inventory)
* The Smart Inventory feature
* Optional: How to structure Ansible content in Git repos
* Optional: How to work with the Tower API

=== So little time and so much to do...

WARNING: To be honest we got carried away slightly while trying to press all these cool features into a two-hours lab session. We decided to flag the last two chapters as "optional" instead of taking them out. If you find the time to run them, cool! If not, the lab guide will stay where it is, feel free to go through these lab tasks later (you don't need a Tower cluster for this).  

=== Want to Use this Lab after Summit?

Definitely, the Asciidoc sources are available here:

*\https://github.com/goetzrieger/ansible-labs/blob/master/tower/ansible_tower_advanced.adoc*

== Your Ansible Tower Lab Environment

In this lab you work in a pre-configured lab environment. You will have access to the following hosts:

[cols="v,v,v,v"]
|===
|Role|Hostname External (if applicable)|Hostname Internal|Internal IP

|Control/Bastion Host, Gitea Repo|control-<GUID>.rhpds.opentlc.com|control.example.com|192.168.0.10
|Ansible Tower Cluster|\https://tower{1-3}-<GUID>.rhpds.opentlc.com|tower{1-3}.example.com|192.168.0.{4,5,6}0
|Ansible Tower Database Host||towerdb.example.com|192.168.0.70
|Managed RHEL7 Host 1||host1.example.com|192.168.0.20
|Managed RHEL7 Host 2||host2.example.com|192.168.0.30
|Ansible Tower Isolated Node||isonode.remote.example.com|172.16.0.10
|Managed Remote Host 1||isohost1.remote.example.com|172.16.0.20
|Managed Remote Host 2||isohost2.remote.example.com|172.16.0.30

|===

TIP: Your lab environment will get a unique *<GUID>*. You will be able to SSH into `control.example.com` using the external hostname `control-<GUID>.rhpds.opentlc.com`, from here you need to SSH into the other hosts to run tasks on the commandline. 

TIP: Ansible Tower has already been installed and licensed for you, the web UI will be reachable over HTTP/HTTPS. 

As you can see the lab environment is pretty extensive. You basically have one network segment with:

* A bastion/control host you access via SSH, the Gitea git repo lives here as well
* A three-node Tower cluster with a separate DB host, accessed via SSH (from control host) or web UI
* Two managed RHEL 7 hosts

And a second network segment with:

* One host that acts as an isolated Tower node that can be reached via SSH from the Tower cluster nodes.
* Two hosts which act as remote managed nodes that can only be reached from/through the isolated node.

A diagram says more then a thousand words:

image::adv_tower_diagram.png[align="center"]

TIP: Access to the isolated node and the managed hosts is actually not restricted in the lab environment. Just imagine access is filtered for educational purposes... ;-)

=== Working the Lab

Some hints to get you started:

* Don't type everything manually, use copy & paste from the browser when appropriate. But don't stop to think and understand... ;-)

* All labs where prepared using *Vim*, but we understand not everybody loves it. Feel free to use alternative editors, in the lab environment we provide *Midnight Commander* (just run *mc*, function keys can be reached via Esc-<n> or simply clicked with the mouse) or *Nano* (run *nano*). Here is a short http://people.redhat.com/grieger/editor_intro_rhel7.html[editor intro, window="_blank"].

TIP: Commands you are supposed to run are shown with or without the expected output, whatever makes more sense in the context. 

TIP: The command line can wrap on the HTML page from time to time. Therefor the 
output is often separated from the command line for better readability by an empty 
line. *Anyway, the line you should actually run should be recognizable by the 
prompt.* :-) 

//== Access your Lab Environment

//include::access_adoc/access_summit19.adoc[]

== Introduction to Ansible Tower Clustering

With version 3.1 Ansible Tower introduced clustering, replacing the redundancy solution configured with the active-passive nodes. Clustering is sharing load between Tower nodes/instances. Each Tower instance is able to act as an entry point for UI and API access.

TIP: Using a load balancer in front of the Tower nodes is possible, but optional because an Ansible Tower cluster can be accessed via all Tower instances.

Each instance in a Tower cluster expands the cluster's capacity to execute jobs. Jobs can and will run anywhere rather than be directed on where to run.

TIP: The Appendix contains some installation considerations and an installer inventory for reference.

=== Access the Tower Web UI

For the first contact to your cluster open your browser and login to all three nodes web UIs (you'll have to accept the self-signed certificates) as:

* user *admin* 
* password *r3dh4t1!*

WARNING: Replace the *<GUID>* string with your GUID!

* *\https://tower1-<GUID>.rhpds.opentlc.com*
* *\https://tower2-<GUID>.rhpds.opentlc.com*
* *\https://tower3-<GUID>.rhpds.opentlc.com*

Just from the web UI you wouldn't know you've got a Tower cluster at your hands here. To learn more about your cluster and it's state, in one of the instances web UI under *ADMINISTRATION* choose *Instance Groups*. Here you will get an overview of the cluster by instance groups. Explore the information provided, of course there is no capacity used yet and no Jobs have run.

Right now we have three instance groups named *dev*, *prod* and *tower*. In a freshly installed Tower install you would only find one, *tower*. From this view you can also see how the instance are distributed over the groups. 

To dig deeper, for every group, click on *INSTANCES* to get more information about the instances allocated to a group. In the instances view you can toggle nodes off/online and adjust the number of forks. You'll learn more about this later.

=== Access you Tower Cluster via SSH

You can also get information about your cluster on the command line. Open a terminal window and start an SSH session to your control host using the external hostname (replace the <GUID> string, key authentication should work automatically):

----
# ssh lab-user@control-<GUID>.rhpds.opentlc.com
----

Then become root:
----
[lab-user@control-<GUID> ~]$ sudo -i
[root@control-<GUID> ~]# 
----

TIP: Remember the control host is named *control-<GUID>.rhpds.opentlc.com* when accessed from the outside, inside the lab environment you can use *control.example.com*.

WARNING: We'll leave out the *<GUID>* part of the prompt from now on for readability.

From `control.example.com` jump to one of the Tower instances, e.g.:

----
[root@control ~]# ssh tower1.example.com
----

And run the following command:

----
[root@tower1 ~]# awx-manage list_instances
[tower capacity=171]
	tower2.example.com capacity=57 version=3.4.1 heartbeat="2019-04-05 12:00:38"
	tower1.example.com capacity=57 version=3.4.1 heartbeat="2019-04-05 11:59:58"
	tower3.example.com capacity=57 version=3.4.1 heartbeat="2019-04-05 12:00:41"

[prod capacity=57]
	tower3.example.com capacity=57 version=3.4.1 heartbeat="2019-04-05 12:00:41"

[dev capacity=57]
	tower2.example.com capacity=57 version=3.4.1 heartbeat="2019-04-05 12:00:38"
----

So what we've got is a three-node Tower cluster, no surprises here. In addition the command tells us the capacity (maximum number of forks/concurrent jobs) per node and for the instance groups. Here the capacity value of 57 is allocated to any of our three nodes. 

TIP: The *awx-manage* (formerly tower-manage) utility can be used to administer a lot of the more internal aspects of Tower. You can e.g. use it to clean up old data, for token and session management and for cluster management.

== There is more to Tower than the Web UI

This is an advanced Tower lab so we don't really want you to use the web UI for everything. Tower's web UI is well done and helps with a lot of tasks, but same as in system administration it's often handy to be able to use the command line or scripts for certain tasks.

We've incorporated different ways to work with Tower in this lab guide and hope you'll find it helpful. The first step we do is install the *tower-cli* utility.

TIP: *tower-cli* is an open source project currently under development and, until a complete implementation occurs, only implements a subset of Towerâ€™s features. Right now you can install `tower-cli` from Python Pip or from the EPEL repository.

We'll install it on your control host using locally cached RPM packages. Exit the SSH session to *tower1.example.com* or open a new one to the control host, then install *tower-cli*:

----
# ssh root@control-<GUID>.rhpds.opentlc.com
#[root@control ~]# yum install python2-ansible-tower-cli -y
ansible localhost, -m yum -a 'name=python2-ansible-tower-cli state=latest'
----

After installing the tool, you have to do some basic configuration (Tower node to connect to, user and password):

----
[root@control ~]# tower-cli config host tower2.example.com
[root@control ~]# tower-cli config username admin
[root@control ~]# tower-cli config password r3dh4t1!
----

TIP: It doesn't really matter what node you connect to.

Now test *tower-cli* is working. First run it without arguments to get a list of resources you can manage with it:

----
[root@control ~]# tower-cli --help
----

And then test something, e.g.:

----
[root@control ~]# tower-cli inventory list
----

TIP: When trying to find a *tower-cli* command line for something you want to do, just move one by one.

Example:

----
[root@control ~]# tower-cli --help
----

Okay, there is an *inventory* resource. Let's see...

----
[root@control ~]# tower-cli inventory --help
----

Well, *create* sounds like what I had in mind. But what arguments do I need? Just run:

----
[root@control ~]# tower-cli inventory create
----

Bingo! Take note of the *REQUIRED* mark.

TIP: When you start using *tower-cli* this file is very helpful as it provides a lot of examples: https://raw.githubusercontent.com/ansible/tower-cli/master/docs/source/cli_ref/examples/fake_data_creator.sh

=== Challenge Lab: tower-cli

To practice your *tower-cli* skills, here is a challenge:

* Try to change the *idle time out* of the Tower web UI, it's 1800 seconds by default. Set it to, say, 7200. Using *tower-cli*, of course.

* Start by looking for a resource type *tower-cli* provides using *--help* that sounds like it has something to do with changing settings.

* Look at the available *tower-cli* commands for this resource type.

* Use the commands to have a look at the parameters settings and change it.

TIP: The configuration parameter is called *SESSION_COOKIE_AGE*

WARNING: *SOLUTION BELOW!*

+++ <details><summary> +++
*>> _Click here for the solution_ <<*
+++ </summary><div> +++

----
[root@control ~]# tower-cli setting
[root@control ~]# tower-cli setting get SESSION_COOKIE_AGE
[root@control ~]# tower-cli setting modify SESSION_COOKIE_AGE 7200
[root@control ~]# tower-cli setting get SESSION_COOKIE_AGE
----

+++ </div></details> +++

If you want to, go to the web UI and check the setting under *ADMINISTRATION->Settings->System*.

== Creating Tower Objects Using `tower-cli`

Next we want to configure Tower so that we can run Ansible jobs. For this we need Inventories, Projects, Credentials and Job Templates. When you first start with Tower, this is usually done via web UI. But using Tower more often and especially when you want to boot-strap a configured Tower from the bottom up it makes sense to do this via *tower-cli* in a scripted way - especially when Ansible is not yet set up properly.

In the first step you will learn to setup the inventory with *tower-cli* step by step to get practice using the tool. For the following steps (Projects, Credentials, Job Templates) we will not go into such detail. Instead we will just explain the actual *tower-cli* commands and put them all into a shell script. This shell script will serve as an example of how to bootstrap a Tower from bottom up, for example for test cases.

=== Create an Inventory

First we create a static inventory, we'll get to dynamic inventories later on. Try to figure out the proper invocation of *tower-cli* yourself and create an inventory name *Example Inventory*.

TIP: Remember how you used the *tower-cli* help to get down to the needed command.

WARNING: *Solution Below*!

+++ <details><summary> +++
*>> _Click here for the solution_ <<*
+++ </summary><div> +++

----
[root@control ~]# tower-cli inventory create --name "Example Inventory" --organization "Default"
----

TIP: You can work with multiple organizations in Tower. In this lab we'll work in the *Default* organization.

+++ </div></details> +++

==== Add Hosts to the Inventory using *tower-cli*

Now that we have the empty inventory created, add your two managed hosts *host1.example.com* and *host2.example.com*, again using *tower-cli*.

WARNING: *Solution Below*!

+++ <details><summary> +++
*>> _Click here for the solution_ <<*
+++ </summary><div> +++

----
[root@control ~]# tower-cli host create --name "host1.example.com" --inventory "Example Inventory"
[root@control ~]# tower-cli host create --name "host2.example.com" --inventory "Example Inventory"
----

+++ </div></details> +++

=== Create script to contain this and all following tower-cli commands

As mentioned one of the puproses of *tower-cli* is to use it to automatically configure more complex Tower setups. In such cases, multiple *tower-cli* commands are put togerther in a script. We follow that practice in our example here, and create a shell script on the control host with all commands you have to run to bootstrap Tower. So in the next few paragraphs we describe the steps to do and describe the corresponding *tower-cli* commands. But we will not execute them, but instead write them into a script.

Create the file *setup-tower.sh* with your favorite editor and add the commands executed above:

----
#!/bin/bash
tower-cli inventory create --name "Example Inventory" --organization "Default"
tower-cli host create --name "host1.example.com" --inventory "Example Inventory"
tower-cli host create --name "host2.example.com" --inventory "Example Inventory"
----

TIP: You have run these commands above already, true. But we want to show how to create the full script here. 

Next, save the script, exit the editor and make the script executable. Then launch it:

----
[root@control ~]# chmod u+x setup-tower.sh
[root@control ~]# ./setup-tower.sh
----

TIP: If you run the script a second time, you will see that *tower-cli* is idempotent, so it's fine that you run the *tower-cli* commands already.

From now on we'll explain the needed comands for each of the next steps and add them to the script step-by-step.

=== Create Machine Credentials

TIP: SSH keys have already been created and distributed in your lab environment and `sudo` has been setup on the managed hosts to allow password-less login for user *ansible* on *control.example.com*.

Now we want to configure the credentials to access our managed hosts from Tower. Configuring credentials with SSH keys from *tower-cli* on the command line is a bit cumbersome as you can see in the following example. Add the following line to to *setup-tower.sh*, but don't run the script yet:

----
tower-cli credential create --name "Example Credentials" \
                     --organization "Default" --credential-type "Machine" \
                     --inputs="{\"username\":\"ansible\",\"ssh_key_data\":\"$(sed -E ':a;N;$!ba;s/\r{0,1}\n/\\n/g' /home/ansible/.ssh/id_rsa)\n\",\"become_method\":\"sudo\"}"
----

The ssh key is read in here via a sub-shell. Since JSON POST data need to be on one line, all new lines in the ssh key file are replaced with a *\n*.

Don't run the shell script yet, first got through the following steps to add all commands to it.

WARNING: As the *tower-cli* commands get longer you'll find we use the back-slash for line wraps to make the commands readable. You can copy the examples or use them without the \ on one line, of course.

=== Using Git for Software Configuration Management (SCM)

Your lab environment includes Gitea, a Git-service that comes with a web ui and much more. Gitea runs on `control.example.com` and can be accessed via HTTP. Go and have a look around by accessing:

*\http://control-<GUID>.rhpds.opentlc.com/gitea*

All repos on Gitea are configured as private, e.g. a login is needed to access the content. The credentials are:

* *User*: git
* *Password*: r3dh4t1!

To configure and use this repository as a *Source Control Management (SCM)* system in Tower you have to create credentials again, this time to access the Git repository over HTTP. This credential is user/password based, and we add the following *tower-cli* command to our *setup-tower.sh* script. Just add it to the script, don't execute it yet.

----
tower-cli credential create --credential-type="Source Control" \
                    --name="Gitea Credentials" \
                    --inputs='{"username": "git", "password": "r3dh4t1!"}' \
                    --organization="Default"
----

WARNING: Note the different *credential-type* *source* instead of *machine* in the command.

=== Create the Project

Now with the SCM credentials configured, the next step is to add a project to import the playbooks. Add the appropriate *tower-cli* line to the script *setup-tower.sh*:

----
tower-cli project create --name="Apache" \
                  --scm-type=git \
                  --scm-url="http://control.example.com/gitea/git/apache.git" \
                  --scm-credential="Gitea Credentials" \
                  --organization "Default" \
                  --scm-clean=true --scm-delete-on-update=true --scm-update-on-launch=true \
                  --wait
----

TIP: Note that the first parameter to *tower-cli* is different here since we work on the resource *project*.

WARNING: Remember you can use `control.example.com` as hostname in *SCM URL* because it resolves inside the environment. For accessing the Gitea web UI in your browser you need to use `\http://control-<GUID>.rhpds.opentlc.com/gitea`.

=== Create a Job Template

Before running an Ansible *Job* from your Tower cluster you must create a *Job Template*, again business as usual for Tower users. Here *tower-cli* will work on the resource *job_template*. Add the following line to your script *setup-tower.sh*. Don't run the script yet.

----
tower-cli job_template create \
                    --name="Install Apache" \
                    --inventory="Example Inventory" \
                    --credential="Example Credentials" \
                    --project=Apache \
                    --playbook=apache_install.yml \
                    --become-enabled="yes"
----

=== Review the final script and execute it

Verify that your script has all the pieces needed for a properly configured Tower:

* inventory with hosts
* machine credentials and credentials for Git
* project
* job template

The final script is also shown here:

----
#!/bin/bash
tower-cli inventory create --name "Example Inventory" --organization "Default"
tower-cli host create --name "host1.example.com" --inventory "Example Inventory"
tower-cli host create --name "host2.example.com" --inventory "Example Inventory"
tower-cli credential create --name "Example Credentials" \
                      --organization "Default" --credential-type "Machine" \
                      --inputs="{\"username\":\"ansible\",\"ssh_key_data\":\"$(sed -E ':a;N;$!ba;s/\r{0,1}\n/\\n/g' /home/ansible/.ssh/id_rsa)\n\",\"become_method\":\"sudo\"}"
tower-cli credential create --credential-type="Source Control" \
                     --name="Gitea Credentials" \
                     --inputs='{"username": "git", "password": "r3dh4t1!"}' \
                     --organization="Default"
tower-cli project create --name="Apache" \
                  --scm-type=git \
                  --scm-url="http://control.example.com/gitea/git/apache.git" \
                  --scm-credential="Gitea Credentials" \
                  --organization "Default" \
                  --scm-clean=true --scm-delete-on-update=true --scm-update-on-launch=true \
                  --wait
tower-cli job_template create \
                     --name="Install Apache" \
                     --inventory="Example Inventory" \
                     --credential="Example Credentials" \
                     --project=Apache \
                     --playbook=apache_install.yml \
                     --become-enabled="yes"
----

Run the script, and verify that all resources were properly created in the web UI.

*Take away:*

It's easy to script Tower's configuration using *tower-cli*.  This way you can bootstrap a new Tower node or script tasks you have to run on a regular basis. You will learn more about the Tower API at the end of the lab.

=== It's a Cluster After All

We are working in a clustered environment. To verify that the resources were created on all instances properly, login to the other Tower instances web UIs (the ones you didn't configured the inventory and credentials on). 

Have a look around, everything we automatically configured on one Tower instance with our script was *synced automatically* to the other nodes. Inventory, credentials, projects, templates, all there.

== Run a Job in a Cluster

After boot-strapping the Tower configuration from bottom up you are ready to start a job in your Tower cluster. In one of the Tower web UI's:

* Open the *Templates* view 
* Look for the *Install Apache* Template you created with the script
* Run it by clicking the rocket icon.

At first this is not different from a standard Tower setup. But as this is a cluster of active Tower instances every instance could have run the job. And the Job output in Tower's web UI doesn't tell you where it run, just the instance group.

=== So what Instance run the Job?

In one of the Tower instances web UI under *ADMINISTRATION* go to the *Instance Groups* view. For the `tower` instance group, the *TOTAL JOBS* counter shows the number of finished jobs. If you click *TOTAL JOBS* you'll get a detailed list of jobs. You should see four jobs. Why? Three of them are the SCM Updates on every node, and the fourth is the actual Playbook run.

To see what instance actually ran your job, go back to the *Instance Groups* view. If you click *INSTANCES* under the *tower* group, you will get an overview of the *TOTAL JOBS* each Tower instance in this group executed. Clicking *TOTAL JOBS* for an instance leads to a detailed job list.

=== But I just want to know on which Instance my Job Ran!

But it would still be nice to see where a job ran (not the other way round) and to get an idea how jobs are distributed to the available instances. For this we can utilize the API:

* First find the job ID: In the web UI access *VIEWS->Jobs*
* The jobs names are prefixed with the job ID, example *3 - Install Apache* 
* With the ID you can query the API for the instance/node the job was executed on

Bring up the SSH session on your control host and run:

WARNING: Replace <ID> with the job ID you want to query!

[subs=+quotes]
----
[root@control ~]# curl -s -k -u admin:r3dh4t1! https://tower2.example.com/api/v2/jobs/*<ID>*/ | python -m json.tool | grep execution_node

    "execution_node": "tower1.example.com",
----

TIP: You can use any method you want to access the API and to display the result, of course. The usage of curl and python-tool was just for example.

=== Via API in the browser

Another way to query the Tower API is using a browser. For example to have a look at the job details (basically what you did above using curl and friends):

* Find the job ID
* Now get the job details via the API interface: 
** Open the URL *\https://tower1-<GUID>.rhpds.opentlc.com/api/v2/jobs/<ID>/* where `<ID>` is the number of the job you just looked up in the UI. 
** Search the page for the string you are interested in, e.g. `execution_node`

TIP: You can of course query any Tower node.

== Tower Instance Groups

Ansible Tower clustering allows you to easily add capacity to your Tower infrastructure by adding instances. What it doesn't allow is to dedicate capacity or nodes to a purpose, be it a group of people, a department or a location. 

In a single-group Tower cluster where all instances are within the `tower` group there is no way to influence what node will run a job, the cluster will take care of scheduling Jobs as it sees fit.

To enable more control over what node is running a job, Tower 3.2 saw the introduction of the instance groups feature. Instance groups allow you to organize your cluster nodes into groups. In turn Jobs can be assigned to Instance Groups by configuring the Groups in Organizations, Inventories or Job Templates.

TIP: The order of priority is *Job Template > Inventory > Organization*. So Instance Groups configured in Job Templates take precedence over those configured in Inventories, which take precedence over Organizations

Some things to keep in mind about Instance Groups:

* Nodes in an Instance Group share a job queue
* You can have as many Instance Groups as you like as long as there is at least one node in the `tower` group
* Nodes can be in one or more Instance Groups
* Instance Groups can not be named `instance_group_tower`!
* Tower instances can't have the same name as an Instance Group

Instance Groups allows for some pretty cool setups, e.g. you could have some nodes shared over the whole cluster (by putting them into all groups) but then have other nodes that are dedicated to one group to reserve some capacity.

WARNING: The base `tower` group does house keeping like processing events from jobs for all groups. This enables the node count of this group to scale with your overall cluster load, even if these nodes are not used to run Jobs.

Talking about the `tower` group: As you have learned this group is crucial for the operations of a Tower cluster. Apart from the house keeping tasks, if a resource is not associated with an Instance Group, one of the nodes from the `tower` group will run the Job. So if there are no operational nodes in the base group, the cluster will not be able to run Jobs.

WARNING: It is important to have enough nodes in the `tower` group

TIP: Here is a great blog post going into Instance Groups with a lot more depth: https://www.ansible.com/blog/ansible-tower-feature-spotlight-instance-groups-and-isolated-nodes.

=== Instance Group Setup

Having the introduction out of the way, let's get back to our lab and give Instance Groups a try. First have a look at your Tower configuration as described in the installers inventory file. In your SSH session on the control host change into the Ansible installer directory and do the following:

[subs=+quotes]
----
[root@control ~]# cd ansible-tower-setup-bundle-3.4.1-1.el7/
[root@control ansible-tower-setup-bundle-3.4.1-1.el7]# cat inventory

[tower]
tower1.example.com
tower2.example.com
tower3.example.com

*[instance_group_prod]
tower3.example.com

[instance_group_dev]
tower2.example.com*

[...]
----

In a basic cluster setup you would just have the `[tower]` base group. In this lab environment two more Instance Groups where already configured, they are marked in bold:

* All instances are in the *tower* base group
* Two more groups (*prod* and *dev*) with one instances each where setup

TIP: Instance groups are prefixed with `instance_group_`.

WARNING: This is not best practice, it's just for the sake of this lab! Any jobs that are launched targeting a group without active nodes will be stuck in a waiting state until instances become available. So one-instance groups are never a good idea.

=== Verify Instance Groups

You can check your instance groups in a number of ways.

==== Via cli

----
[root@control ~]# tower-cli instance_group list
== ===== ======== ================= 
id name  capacity consumed_capacity 
== ===== ======== ================= 
 1 tower      171                 0
 2 prod        57                 0
 3 dev         57                 0
== ===== ======== =================
----

==== Via API

You can again query the API to get this information. Either use the browser to access the URL `\https://tower1-<GUID>.rhpds.opentlc.com/api/v2/instance_groups/` or use curl to access the API from the command line:

TIP: The curl command has to be on one line.

----
[root@control ~]# curl -s -k -u admin:r3dh4t1! https://tower2.example.com/api/v2/instance_groups/| python -m json.tool

{
    "count": 1,
    "next": null,
    "previous": null,
    "results": [
        {
            "capacity": 171,
            "committed_capacity": 0,
            "consumed_capacity": 0,
            "controller": null,
            "created": "2019-03-01T16:39:08.293548Z",
            "id": 1,
            "instances": 3,
            "jobs_running": 0,
            "jobs_total": 150,
            "modified": "2019-03-01T16:39:08.343125Z",
            "name": "tower",
            "percent_capacity_remaining": 100.0,
            "policy_instance_list": [
                "tower3.example.com",
                "tower1.example.com",
                "tower2.example.com"
            ],
            "policy_instance_minimum": 0,
            "policy_instance_percentage": 0,
            "related": {
                "instances": "/api/v2/instance_groups/1/instances/",
                "jobs": "/api/v2/instance_groups/1/jobs/"
            },
            "type": "instance_group",
            "url": "/api/v2/instance_groups/1/"
        }
    ]
}
----

==== Via the Web UI

Open the URL `\https://tower1-<GUID>.rhpds.opentlc.com/#/instance_groups` in your browser.

In the *INSTANCE GROUPS* overview all instance groups are listed with details of the group itself. It shows infrormation like number of instances in the group and running jobs and finished jobs. As you've seen before for the *tower* global group, the current capacity of the instance groups is shown in a live view.  This provides quick insight if there are capacity problems.

=== Deactivating Tower Instances

While in the *INSTANCES GROUPS* overview click the *INSTANCES* link for, say, the *dev* group. In the next view you'll see a slide button next to each Tower instance (only one in this case). 

* The button should be set to "ON" image:on_off.png[20,20]. Clicking it would deactivate the corresponding instance and would prevent that further jobs are assigned to it. 
* Running jobs on an instance which is set to "OFF" are finished in a normal way. 
* The slider can change the amount of RAM and thus the amount of forks scheduled on an instance. This way it is possible to influence in which ratio the jobs are assigned.

== Start Parallel Jobs across Instances

The real power of instance groups is revealed when multiple jobs are started, and they are assigned to different Tower nodes. To launch parallel jobs we will set up a workflow with multiple concurrent jobs. 

=== Lab Scenario

During this lab we'll focus on security compliance according to STIG, CIS and so on. Often these compliance rules are enforced by executing an Ansible task per each requirement. This makes documentation and audit easier. 

Compliance requirements are often grouped into independent categories. The tasks can often be executed in parallel because they do not conflict with each other. 

In our demo case we use three playbooks which:

* ensure the absence of a few packages (STIG)
* ensure configuration of PAM and login cryptography (STIG)
* ensure absence of services and kernel modules (CIS).

The Playbooks can be found in the "compliance" repository on Gitea: `\http://control-<GUID>.rhpds.opentlc.com/gitea/git/compliance`. Head over to Gitea's web UI and have a look at the Playbooks to see what they do.

=== Prepare the Compliance Lab

==== First Step: Add Repository to Tower

The compliance repository needs to be added as project. Feel free to use the web UI or use *tower-cli* like shown below.

----
[root@control ~]# tower-cli project create -n "Compliance Repository" \
                    --organization Default \
                    --scm-type git \
                    --scm-url http://control.example.com/gitea/git/compliance.git \
                    --scm-clean 1 \
                    --scm-update-on-launch 1 \
                    --scm-credential "Gitea Credentials"
----

TIP: It should again be obvious that using tower-cli is much faster than clicking through multiple steps in a web interface.

Have a look at the status of the Project:

----
[root@control ~]# tower-cli project status -n "Compliance Repository"
----

==== Second Step: Create three Templates

As mentioned the repository contains three Playbooks to enforce different compliance requirements. We again create these three templates via `tower-cli`:

----
[root@control ~]# tower-cli job_template create -n "Compliance STIG packages" \
                    --job-type run -i "Example Inventory" \
                    --project "Compliance Repository" \
                    --playbook "stig-packages.yml" \
                    --credential "Example Credentials" \
                    --become-enabled 1
----

----
[root@control ~]# tower-cli job_template create -n "Compliance STIG config" \
                    --job-type run -i "Example Inventory" \
                    --project "Compliance Repository" \
                    --playbook "stig-config.yml" \
                    --credential "Example Credentials" \
                    --become-enabled 1
----

----
[root@control ~]# tower-cli job_template create -n "Compliance CIS" \
                    --job-type run -i "Example Inventory" \
                    --project "Compliance Repository" \
                    --playbook "cis.yml" \
                    --credential "Example Credentials" \
                    --become-enabled 1
----

=== Create Parallel Workflow

To enable parallel execution of the tasks in these job templates, we will create a workflow. We'll use the web UI because using *tower-cli* is a bit too involved for a lab. Workflows are configured in the *Templates* view, you might have noticed you can choose between *Job Template* and *Workflow Template* when adding a template.

* Go to the *Templates* view and click the image:green_plus.png[20,20] button. This time choose *Workflow Template*
** *NAME:* Compliance Workflow
** *ORGANIZATION:* Default
* Click *SAVE*
* Now the *WORKFLOW VISUALIZER* button becomes active, click it to start the graphical editor.
* Click on the *START* button, a new node opens. To the right you can assign an action to the node, you can choose between *JOBS*, *PROJECT SYNC* and *INVENTORY SYNC*.
* In this lab we'll link multiple jobs to the *START*, so select the *Compliance STIG packages* job and click *SELECT*. The node gets annotated with the name of the job.
* Click on the *START* button again, another new node opens.
* Select the *Compliance STIG config* job and click *SELECT*. The node gets annotated with the name of the job.
* Click on the *START* button again, another new node opens.
* Select the *Compliance CIS* job and click *SELECT*. The node gets annotated with the name of the job.
* Click *SAVE*
* In the workflow overview window, again click *SAVE*

You have configured a Workflow that is not going through templates one after the other but rather executes three templates in parallel.

=== Execute and Watch

Your workflow is ready to go, launch it.

* In the *Templates* view launch the *Compliance Workflow* by clicking the rocket icon.
* Wait until the job has finished.

Go to the *Instance Groups* view and find out how the jobs were distributed over the instances:

* Open the *INSTANCES* view of the tower instance group.
* Look at the *TOTAL JOBS* view of the three instances
* Because the Job Templates called in the workflow didn't specify an instance group, they were distributed evenly over the instances. 

Now deactivate instance *tower1.example.com* with the image:on_off.png[20,20] button and wait until it is shown as deactivated. Make a (mental) note of the *TOTAL JOBS* counter of the instance. Go back to the list of templates and launch the workflow *Compliance Workflow* again.

Go back to the *Instance Groups* view, get back to the instance overview of instance group *tower* and verify that the three Playbooks where launched on the remaining instances and the *TOTAL JOBS* counter of instance *tower1.example.com* didn't change.

Activate *tower1.example.com* again by pressing image:on_off.png[20,20] a second time.

=== Using Instance Groups

So we have seen how a Tower cluster is distributing jobs over Tower instances by default. We have already created instance groups which allow us to take control over what job is executed on which node, so let's use them.

To make it easier to spot where the jobs were run let's first empty the jobs history. This can be done using *awx-manage* on one of the Tower instances. From your control node SSH into one of the Tower hosts and run the command:

----
[root@tower1 ~]# awx-manage cleanup_jobs  --days=0
----

==== Assign Jobs to Instance Groups

One way to assign a job to an instance group is in the job template. As our compliance workflow uses three job templates, do this for all of them:

* In the web UI, go to *RESOURCES->Templates*
* Open one of the three compliance templates
* In the *Instance Groups* field, choose the *dev* instance group and click *SAVE*.
* Click *SAVE* for the template and do this for the other two compliance templates, too.

Now the jobs that make up our *Compliance Workflow* are all configured to run on the instances of the *dev* instance group.

==== Run the Workflow

You have done this a couple of times now, you should get along without detailed instructions.

* Run the *Compliance Workflow* 
* What would you expect? On what instance(s) should the workflow jobs run?
* Verify!

TIP: *Result:* The workflow and the associated jobs will run on *tower2.example.com*. Okay, big surprise, in the *dev* instance group is only one instance.

But what's going to happen if you disable this instance?

* Disable the *tower2.example.com* instance in the *Instance Groups* view.
* Run the workflow again.
* What would you expect? On what instance(s) should the workflow jobs run?
* Verify!

TIP: *Result:* The workflow and the associated jobs will stay in pending state because there are no instance available in the *dev* instance group.

What's going to happen if you enable the instance again?

* Go to the *Instance Groups* view and enable *tower2.example.com* again.
* Check in the *Jobs* and *Instance Groups* view what's happening.

TIP: *Result:* After the instance is enabled again the jobs will pickup and run on *tower2.example.com*.

WARNING: At this point make sure the instances you disabled in the previous steps are definitely enabled again! Otherwise subsequent steps might fail...

== Isolated Nodes

Ansible is used to manage complex infrastructures with machines and networks living in multiple separate datacenters, servers behind firewalls or in cloud VPCs, and remote locations only reachable over unstable links.  Some of these links may not survive the length of a job run. In cases like these it's often better to run automation local to the nodes.

To solve this, Tower provides Isolated Nodes:

* Isolated nodes *don't have a full installation of Tower*, but a minimal set of utilities used to run jobs.
* It can be deployed behind a firewall/VPC or in a remote datacenter, only *ingress SSH traffic* from a *controller* instance to the *isolated* instances is required. 
* When a job is run that targets things managed by the isolated node, the *job* and its *environment* will be *pushed to the isolated node* over SSH
* Periodically, the *master Ansible Tower cluster will poll the isolated node* for status on the job. 
* When the *job finishes*, the job status will be *updated in Ansible Tower*

=== Setting Up Isolated Nodes

Isolated nodes are defined in the inventory file (same as instance groups) and setup by the Ansible Tower installer. Isolated nodes make up their own instance groups that are specified in the inventory file prefixed with *isolated_group_*. In the isolated instance group model, only specific *controller* Tower instance groups interact with *isolated* nodes.

So for the fun of it, let's set one up.

First have a look at our setup as described in the installers inventory file. In your SSH session on the control host change into the Ansible installer directory and do the following:

----
[root@control ~]# cd ansible-tower-setup-bundle-3.4.1-1.el7
[root@control ansible-tower-setup-bundle-3.4.1-1.el7]# cat inventory

[tower]
tower1.example.com
tower2.example.com
tower3.example.com

[instance_group_prod]
tower3.example.com

[instance_group_dev]
tower2.example.com

[database]
towerdb.example.com

[...]
----

We have the `tower` base group and two instance groups. For the isolated node we will define a new *isolated_group_* named *dmz* with one entirely new node (plain RHEL 7 for now), called `isonode.remote.example.com` which we'll use to manage other hosts in the remote location. Add the isolated node by editing the inventory:

TIP: Changes are shown in *bold* type for clarity only!

[subs=+quotes]
----
[tower]
tower1.example.com
tower2.example.com

[instance_group_prod]
tower3.example.com

[instance_group_dev]
tower2.example.com

*[isolated_group_dmz]
isonode.remote.example.com

[isolated_group_dmz:vars]
controller=tower*

[database]
towerdb.example.com

[...]
----

TIP: Each isolated group must have a controller variable set. This variable points to the instance group that manages tasks that are sent to the isolated node. That instance group will be responsible for starting and monitoring jobs on the isolated node. In this case, we're using the main *tower* instance group to manage this isolated group.

After editing the inventory, start the installer to make the desired changes:

----
[root@control ansible-tower-setup-bundle-3.2.5-1.el7]# ./setup.sh
----

TIP: During installation of an isolated node, a randomized RSA key is generated and distributed as an authorized key to the *isolated* instances.

=== Verify Isolated Nodes

Isolated groups can be listed in the same way like instance groups and Ansible Tower cluster configuration. So the methods listed above discussing instance groups also applies to isolated nodes. For example, using `tower-cli`:

[subs=+quotes]
----
[root@control ~]# tower-cli instance_group list
== ======== ======== =================
id   name   capacity consumed_capacity
== ======== ======== =================
 1 tower         171                 0
 2 prod           57                 0
 3 dev            57                 0
 *4 dmz            57                 0*
== ======== ======== =================
----

Like other instance groups, isolated node groups can be assigned at the level of an organization, an inventory, or an individual job template.

=== Create Isolated Node specific Inventory

Let's assume we have a DMZ setup with two hosts we want to manage siloed off from the rest of the infrastructure called *isohost{1,2}.remote.example.com*. The isolated node we configured above is located in the same DMZ and is able to connect to the DMZ hosts.

Now create a new inventory in your Tower cluster. You can do this with `tower-cli` like we did above, or you use the web UI. Why not use the web UI for a change?

In the Tower web UI under *RESOURCES*, click *Inventories*:

* Click the image:green_plus.png[20,20] button to add a new inventory
* *NAME:* Remote Inventory
* *ORGANIZATION:* Default
* *INSTANCE GROUPS:* Pick the instance group you created in the last step, `dmz`
* Click *SAVE*

After you've clicked *SAVE*, you can add hosts: the button for the hosts management image:tower_hosts.png[40,40] is active now. Click on it to access the hosts overview. There are no hosts right now, so let's add some:

* Click the image:green_plus.png[20,20] button to add a new host
* *NAME:* `isohost1.remote.example.com`
* Click *SAVE*

Repeat the steps for a second host called `isohost2.remote.example.com`.

=== Create Template for Isolated Node

Next we need to assign a template to the nodes. Since those nodes are in a DMZ, we certainly have to ensure their compliance. Thus we are going to make sure that they are following our CIS guidelines - and will set up a template executing the CIS playbook on them.

Go to *Templates* in the *RESOURCES* section of the menu, click the image:green_plus.png[20,20] button and choose *Job Template*.

* *NAME:* Remote CIS Compliance
* *JOB TYPE:* Run
* *INVENTORY:* Remote Inventory
* *PROJECT:* Compliance Repository
* *PLAYBOOK:* `cis.yml`
* *CREDENTIAL:* Example Credentials
* *INSTANCE GROUPS:* `dmz`
* We need to run the tasks as root so check *Enable privilege escalation*
* Click *SAVE*

Next, launch the template:

* In the *Templates* view launch the *Remote CIS Compliance* job by clicking the rocket icon.
* Wait until the job is finished.

=== Verify Results

Last but not least, let's check that the job was indeed executed by the isolated node `isonode.remote.example.com`: 

* Go to *Instance Groups* in the *ADMINISTRATION* section of the web UI
* Click on the *dmz* group. 
* Click on the jobs button at the top to see the executed job.

== Advanced Inventories

In Ansible and Ansible Tower, as you know, everything starts with an inventory. There are a several methods how inventories can be created, starting from simple static definitions over importing inventory files to dynamic and smart inventories.

In real life it's very common to deal with external dynamic inventory sources (think cloud). In this chapter we'll introduce you to building dynamic inventories using custom scripts. Another great feature of Tower to deal with inventories is the Smart Inventory feature which you'll do a lab on as well.  

=== Dynamic Inventories

Quite often just using static inventories will not be enough. You might be dealing with ever-changing cloud environments or you have to get your managed systems from a CMDB or other sources of truth.

Tower includes built-in support for syncing dynamic inventory from cloud sources such as Amazon AWS, Google Compute Engine, among others. Tower also offers the ability to use custom scripts to pull from your own inventory source.

In this chapter you'll get started with dynamic inventories in Tower. Aside from the build-in sources you can write inventory scripts in any programming/scripting language that you have installed on the Tower machine. To keep it easy we'll use a most simple custom inventory script using... Bash! Yes!

TIP: Don't get this wrong... we've chosen to use Bash to make it as simple as possible to show the concepts behind dynamic and custom inventories. Usually you'd use Python or some other scripting/programming language.

==== The Inventory Source

First you need a source. In *real life* this would be your *cloud provider, your CMDB or what not*. For the sake of this lab we have the web server on control.example.com configured to hand out a static file to be our source.

Open an SSH session from the control host to one of your Tower-Nodes and query your external inventory source:

----
[root@tower1 ~]# curl control.example.com:/pub/inventory_list
{
    "dyngroup":{
        "hosts":[
            "cloud1.cloud.example.com",
            "cloud2.cloud.example.com"
        ],
        "vars":{
            "var1": true
        }
    },
    "_meta":{
        "hostvars":{
            "cloud1.cloud.example.com":{
                "type":"web"
            },
            "cloud2.cloud.example.com":{
                "type":"database"
            }
        }
    }
}
----

Well, this is handy, the output is already configured as JSON like Ansible would expect... ;-) 

WARNING: Okay, seriously, in real life your script would likely get some information from your source system, format it as JSON and return the data to Tower.

==== The Custom Inventory Script

An inventory script has to follow some conventions. It must accept the *--list* and *--host <hostname>* arguments. When it is called with *--list*, the script must output a JSON-encoded data containing all groups and hosts to be managed. When called with *--host <hostname>* it must return an JSON-formatted hash or dictionary of host variables (can be empty).

As looping over all hosts and calling the script with *--host* can be pretty slow, it is possible to return a top level element called "_meta" with all of the host variables in one script run. And this is what we'll do. So this is our custom inventory script:

----
#!/bin/bash

if [ "$1" == "--list" ] ; then
  curl control.example.com:/pub/inventory_list
elif [ "$1" == "--host" ]; then
  echo '{"_meta": {"hostvars": {}}}'
else
  echo "{ }"
fi
----

What it basically does is to return the data collected by curl when called with *--list* and as the data includes *_meta* information about the host variables Ansible will not call it with *--host*. The curl command is of course the place where your script  would get data by whatever means, format it as proper JSON and return it.

But before we integrate the custom inventory script into our Tower cluster, it's a good idea to test it on the commandline first:

* Log in to one of the Tower nodes if you don't have an SSH session open:

----
[root@control ~]# ssh tower1.example.com
----

* Create the file dyninv.sh with the content shown above
* Make the script executable:
----
[root@tower1 ~]# chmod +x dyninv.sh
----
* Execute it:

----
[root@tower1 ~]# ./dyninv.sh --list
{
    "dyngroup":{
        "hosts":[
            "cloud1.cloud.example.com",
            "cloud2.cloud.example.com"
        ],
        "vars":{
            "var1": true
        }
    },
    "_meta":{
        "hostvars":{
            "cloud1.cloud.example.com":{
                "type":"web"
            },
            "cloud2.cloud.example.com":{
                "type":"database"
            }
        }
    }
}
----

The script should output the JSON-formatted output shown above.

As simple as it gets, right? More information can be found https://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html[here]

So now you have a source of (slightly static) dynamic inventory data (talk about oxymorons...) and a script to fetch and pass it to Tower. Now you need to get this into Tower.

==== Integrate into Tower

The first step is to add the inventory script to Tower:

* In the web UI, open *RESOURCES->Inventory Scripts*.
* To create a new custom inventory script, click the image:green_plus.png[20,20] button.
* Fill in the needed data:
** *NAME:* Cloud Inventory
** Copy the Bash script from above and paste it into the *CUSTOM SCRIPT* field
* Click *SAVE*

Finally the new inventory script can be used in an actual *Inventory*.

* Go to *RESOURCES->Inventories*
* Click the image:green_plus.png[20,20] button and choose *Inventory*.
* *NAME:* Cloud Inventory
* Click *SAVE*
* The *SOURCES* button on top becomes active now, click it
* Click the image:green_plus.png[20,20] to add a new source
* *NAME:* Cloud Custom Script
* From the *SOURCE* drop-down choose *Custom Script*
* Now the dialog for the source opens, your custom script *Cloud Inventory* should already be selected in the *CUSTOM INVENTORY SCRIPT*.
* Under *UPDATE OPTIONS* check *Overwrite* and *Overwrite Variables*
* Click *SAVE*

To sync your new source into the inventory:

* Open the *Cloud Inventory* again
* Click the *SOURCES* button
* To the right click the circular arrow to start the sync process for your custom source.
* After the sync has finished click the *HOSTS* button.

You should now see a list of hosts according to what you got from the curl command above. Click the hosts to make sure the host variables are there, too.

==== Now to the Dynamic Part...

To mimic the dynamic nature of the inventory, adapt the file we are using as inventory source.

* Open an SSH session to your control host (if it's not open anyway).
* Edit the file `/var/www/html/pub/inventory_list` to look like this (i.e. add another host):

WARNING: Either copy & paste the content or make sure to take care of structure (especially the commas...) to get proper JSON!

----
{
    "dyngroup":{
        "hosts":[
            "cloud1.cloud.example.com",
            "cloud2.cloud.example.com",
            "cloud3.cloud.example.com"
        ],
        "vars":{
            "var1": true
        }
    },
    "_meta":{
        "hostvars":{
            "cloud1.cloud.example.com":{
                "type":"web"
            },
            "cloud2.cloud.example.com":{
                "type":"database"
            },
            "cloud3.cloud.example.com":{
                "type":"database"
            }
        }
    }
}
----

After saving the file:

* Go back to web UI, open the *Cloud Inventory* inventory
* Click the *SOURCES* button and re-sync the *Cloud Custom Script* source.
* Open the *HOSTS* view again and make sure you have three hosts listed.

*What is the take away?*

Using this simple example you have:

* Created a script to query an inventory source
* Integrated the script into Tower
* Populated an inventory using the custom script
* Changed the source to test the dynamic nature of the inventory

=== Smart Inventories

You will most likely have inventories from different sources in your Tower installation. Maybe you have a local CMDB, your virtualization management and your public cloud provider to query for managed systems. Imagine you now want to run automation jobs across these inventories on hosts matching certain search criteria.

This is where Smart Inventory comes in. A Smart Inventory is a collection of hosts defined by a stored search. Search criteria can be host attributes (like groups) or facts (such as installed software, services, hardware or whatever information Ansible pulls). A Smart Inventory can be viewed like a standard inventory and used with job runs.  

The base rules of a search are:

* A search typically consists of a field (left-hand side) and a value (right-hand side)
* A colon separates the field that you want to search from the value
* A search string without a colon is treated as a simple string

==== A Simple Smart Inventory

Let's start with a simple string example. In your Tower web UI, open the *RESOURCES->Inventories* view. Then click the image:green_plus.png[20,20] button and choose to create a new *Smart Inventory*. In the next view:

* *NAME:* Smart Inventory Simple
* Click the magnifiying glas icon next to *SMART HOST FILTER* 
* A window *DYNAMIC HOSTS* opens, here you define the search query

To start with you can just use simple search terms. Try *cloud* or *remote.example.com* as search terms and see what you get after hitting *ENTER*.

TIP: Search terms are automatically saved so make sure to hit *CLEAR ALL* to clear the saved search when testing expressions.

Or what about searching by inventory groups? In the *SEARCH* field enter *groups.name:dyngroup*. After hitting *ENTER* the hosts from the dynamic inventory exercise should show up.

When your search returns the expected results, hit *SAVE* for the *DYNAMIC HOSTS* window and again for the Smart Inventory. Now your Smart Inventory is usable for executing job templates!

TIP: You may press the *KEY* button to get a feeling along which fields you can search. Browsing through the API becomes necessary to understand which related fields have which attributes (e.g. name for groups).

==== Build Smart Inventories with Facts

As you know Ansible can collect facts from managed hosts to be used in Playbooks. But before Ansible Tower 3.2 facts where only kept during a Playbook run. Ansible Tower 3.2 introduced an *integrated fact cache* to keep host facts for later usage and better performance. This is how we can use facts in searches for Smart Inventories.

===== Enable Fact Caching

WARNING: Fact caching is not enabled by default!

Fact caching can be enabled for *Templates* and is not enabled by default. So first we have to enable it. Check *host1.example.com* and *host2.example.com* have no facts stored:

* In *RESOURCES->Inventories* open the *Example Inventory* and click the *HOSTS* button.
* Now inspect both hosts by opening the host details and clicking the *FACTS* button at the top.  
* For both hosts the *FACTS* field should be empty

Now enable fact caching for the *Install Apache* template:

* In *RESOURCES->Templates* open the *Install Apache* template.
* Check the *Use Fact Cache* tick box and click *SAVE*

To gather and save the facts you have to run the job template.

* In the *Templates* list start *Install Apache* by clicking the rocket icon

Now enable fact caching for the *Remote CIS Compliance* template and run it, too. This way we'll get cached facts for the isolated hosts. 

After you run the templates go back to the host details like you did above and check the *FACTS* fields for 

* *host1.example.com* and *host2.example.com* (from the *Example Inventory*)
* *isohost1.remote.example.com* and *isohost2.remote.example.com*. 

The hosts facts should now be populated with a lot of facts.

===== Use Facts in Smart Inventory Searches

Now that we got the facts for the hosts in the facts cache, we can use facts in our searches. 

* Create a new Smart Inventory named *Smart Inventory Facts*
* Open the *SMART HOST FILTER* window to enter the search

To search for facts the search field (left side of a search query) has to start with *ansible_facts.* followed by the fact. The value is separated by a colon on the right side.

WARNING: No blank between field and value is allowed!

So what could we search for... start to look at the facts of a host. As all hosts are Red Hat, searching for the fact *ansible_distribution:RedHat* won't be too exciting. Ah, what the heck, just try it:

* Put *ansible_facts.ansible_distribution:RedHat* in the search field
* Run the search by hitting *ENTER*

There should be no surprises: All hosts you have run a fact-caching enabled template on should show up. But there is a fact that should differ: the remote hosts have a different kernel version. Why not use this in the search? Again in the *DYNAMIC HOSTS* window of a Smart Inventory:

* Use this query: *ansible_facts.ansible_kernel:3.10.0-957.1.3.el7.x86_64*
* This should only return *host1.example.com* and *host2.example.com*

Look up the kernel version for the *isohost1.remote.example.com* and *isohost2.remote.example.com* in their respective facts and use it in a query. The query should now return only the remote hosts.

===== Nested Facts

If a fact is deeper in the structure like this:

----
ansible_eth0:
  active: true
----

The search string would look like this: *ansible_facts.ansible_eth0.active:true*

==== Challenge Lab: Facts

So a small challenge: Find out if all hosts have the SElinux mode set to "enforcing".

* Find the fact to use by looking at the host facts
* Create a Smart Inventory
* Create the proper search string

+++ <details><summary> +++
*>> _Click here for the solution_ <<*
+++ </summary><div> +++

The search string to use is: *ansible_facts.ansible_selinux.mode:enforcing*

It should return the remote hosts only.
+++ </div></details> +++

== OPTIONAL: Well Structured Content Repositories

It's a common part of the learning curve for Ansible and Ansible Tower: At some point you will have written so many playbooks that a need for structure comes up. Where to put the Playbooks, what about the Templates, Files and so on.

The main recommendations are:

* Put your content in a version control system like Git or SVN. This comes naturally since Ansible code is usually in text form anyway, and thus can be managed easily. 
* Group your code by logical units, called "link:https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html[roles]" in Ansible.
** Example:  have all code, config templates and files for the apache web server in one role, and all code, configuration and sql statements for the database in another role. That way the code becomes much better to read and handle, and roles can be made re-usable and shared between projects, teams or with the global community.

Of course, what structure works best in the end depends on the individual requirements, but we will highlight some common ground rules which apply to almost all use cases.

The first recommendation is to separate _specific code_ from _reusable/generic code_ from _data_:

specific code:: Playbooks and their direct dependencies which are not shared outside the realm of the project or team. 

generic code:: All content that will be used across multiple projects. 

data:: This is mostly the inventory or the inventory scripts and the corresponding variables for hosts and groups. In many use cases it is advisable to have a dedicated inventory for each life-cycle environment. 

TIP: Data content files can be in the same Git repository, each in its own directory (e.g. dev, test, qa, prod). Alternatively, for example in larger environments or with dedicated teams per environment there can be one Git repository for each environment. We recommend to put special focus on link:https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html#splitting-out-host-and-group-specific-data[splitting out host and group data].

CAUTION: Be careful to _not_ have separate code repositories for each environment. It would go against the purpose of testing the _same_ code as you push it through your life-cycle, only varying the data / inventory. If you have difficulties to keep the same code throughout all your environments we recommend to re-think the structure of cour code and what you put into your inventory.

=== Example repository

So, let's get started with an example. The content and repo-structure in this lab is aligned to the link:https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html#content-organization[Ansible best practices] and is explained in more detail there.

Since we want to store all content in a repository, we will first create an empty Git repository on our Gitea server. Access the Gitea web UI via

*\http://control-<GUID>.rhpds.opentlc.com/gitea*.

Login via the already well known credentials:

* *User*: git
* *Password*: r3dh4t1!

* In the upper right corner, click on the plus sign, and in the opening hover menu click on *New Repository*.
* Set the *Repository Name*: structured-content
* Click the button *Create Repository* at the end of the page.

Next we will clone the repository on the control host. To enable you to work with git on the commandline the SSH key for user *ansible* was already added to the Gitea user *git*. Next, clone the repository on the control machine:

----
[root@control ~]# su - ansible
[ansible@control ~]$ git clone git@control.example.com:/git/structured-content.git
[ansible@control ~]$ cd structured-content/
----

TIP: The repository is currently empty. 

you are now going to add some default directories and files:

----
[ansible@control structured-content]$ touch {staging,production}
----

This command creates two inventory files: in this case we have different stages with different hosts which we keep them in separate inventory files. Note that those files are right now still empty and need to be filled with content to work properly.

In the current setup we have two instances. Let's assume that `host1.example.com` is part of the staging environment, and `host2.example.com` is part of the production environment. To reflect that in the inventory files, edit the two empty inventory files to look like this:

----
[ansible@control structured-content]$ cat staging
[staging]
host1.example.com
----

----
[ansible@control structured-content]$ cat production
[production]
host2.example.com
----

Next we add some directories: 

* A directories for host and group variables
* A *roles* directory where the main part of our automation logic will be in.
* For demonstration purpose we also will add a *library* directory: it can contain Ansible code related to a project like custom modules, plugins, etc.

----
[ansible@control structured-content]$ mkdir -p {group_vars,host_vars,library,roles}
----

Now to the two roles we'll use in this example. First we'll create a structure where we'll add content later. This can easily be achieved with the command `ansible-galaxy`: it creates *role skeletons* with all appropriate files, directories and so on already in place.

----
ansible-galaxy init --offline --init-path=roles security
ansible-galaxy init --offline --init-path=roles apache
----

IMPORTANT: Even if a good role is generally self-explanatory, it still makes sense to have proper documentation. The right location to document roles is the file *meta/main.yml*.

The roles are empty, so we need to add a few tasks to each. In the last chapters we set up an Apache webserver and used some security tasks. Let's add that code to our roles by editing the two task files:

WARNING: If you copy and paste text in VI under a comment (#) character, Vi might (depending on settings) add comment signs to the start of each new line. Probably not what you want. Because the role files are being created with a comment line after the YAML start (---), make sure to delete these lines before pasting the content.   

----
[ansible@control structured-content]$ cat roles/apache/tasks/main.yml
---
# tasks file for apache
- name: latest Apache version installed
  yum:
    name: httpd
    state: latest
- name: latest firewalld version installed
  yum:
    name: firewalld
    state: latest
- name: firewalld enabled and running
  service:
    name: firewalld
    enabled: true
    state: started
- name: firewalld permits http service
  firewalld:
    service: http
    permanent: true
    state: enabled
    immediate: yes
- name: Apache enabled and running
  service:
    name: httpd
    enabled: true
    state: started
----

----
[ansible@control structured-content]$ cat roles/security/tasks/main.yml
---
# tasks file for security
- name: "HIGH | RHEL-07-010290 | PATCH | The Red Hat Enterprise Linux operating system must not have accounts configured with blank or null passwords."
  replace:
    dest: "{{ item }}"
    follow: true
    regexp: 'nullok ?'
  with_items:
    - /etc/pam.d/system-auth
    - /etc/pam.d/password-auth

- name: "MEDIUM | RHEL-07-010210 | PATCH | The Red Hat Enterprise Linux operating system must be configured to use the shadow file to store only encrypted representations of passwords."
  lineinfile:
    dest: /etc/login.defs
    regexp: ^#?ENCRYPT_METHOD
    line: "ENCRYPT_METHOD SHA512"

- name: "SCORED | 1.1.1.2 | PATCH | Remove freevxfs module"
  modprobe:
    name: freevxfs
    state: absent
----

We also need to create a playbook to call the roles from. This is often call `site.yml`, since it keeps the main code for the setup of our environment. Create the file:

----
[ansible@control structured-content]$ cat site.yml 
---
- name: Execute apache and security roles
  hosts: all

  roles:
    - { role: apache}
    - { role: security }
----

So we have prepared a basic structure for quite some content - call `tree` to look at it.

+++ <details><summary> +++
*>> _Click here to see how it should look like_ <<*
+++ </summary><div> +++
----
[ansible@control structured-content]$ tree
.
â”œâ”€â”€ group_vars
â”œâ”€â”€ host_vars
â”œâ”€â”€ library
â”œâ”€â”€ production
â”œâ”€â”€ roles
â”‚Â Â  â”œâ”€â”€ apache
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ defaults
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ main.yml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ files
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ handlers
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ main.yml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ meta
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ main.yml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ README.md
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ tasks
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ main.yml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ templates
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ tests
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ inventory
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ test.yml
â”‚Â Â  â”‚Â Â  â””â”€â”€ vars
â”‚Â Â  â”‚Â Â      â””â”€â”€ main.yml
â”‚Â Â  â””â”€â”€ security
â”‚Â Â      â”œâ”€â”€ defaults
â”‚Â Â      â”‚Â Â  â””â”€â”€ main.yml
â”‚Â Â      â”œâ”€â”€ files
â”‚Â Â      â”œâ”€â”€ handlers
â”‚Â Â      â”‚Â Â  â””â”€â”€ main.yml
â”‚Â Â      â”œâ”€â”€ meta
â”‚Â Â      â”‚Â Â  â””â”€â”€ main.yml
â”‚Â Â      â”œâ”€â”€ README.md
â”‚Â Â      â”œâ”€â”€ tasks
â”‚Â Â      â”‚Â Â  â””â”€â”€ main.yml
â”‚Â Â      â”œâ”€â”€ templates
â”‚Â Â      â”œâ”€â”€ tests
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ inventory
â”‚Â Â      â”‚Â Â  â””â”€â”€ test.yml
â”‚Â Â      â””â”€â”€ vars
â”‚Â Â          â””â”€â”€ main.yml
â”œâ”€â”€ site.yml
â””â”€â”€ staging
----
+++ </div></details> +++

Since we so far created the code only locally on the control host, we need to add it to the repository and push it:

----
[ansible@control structured-content]$ git add production roles site.yml staging 
[ansible@control structured-content]$ git commit -m "Adding inventories and apache security roles"
[ansible@control-dff2 structured-content]$ git push
----

Why not head over to Gitea's web UI to make sure the files are there?

=== Launch it!

==== From the Command Line

The code can now be launched. We start at the command line. Call the playbook `site.yml` with the appropriate inventory and privilege escalation:

----
[ansible@control structured-content]$ ansible-playbook -i staging site.yml -b
---- 

Watch how the changes are done to the target machines. Afterwards, execute the Playbook against the production stage: 

----
[ansible@control structured-content]$ ansible-playbook -i production site.yml -b
----

==== From Tower

The new repository needs to be added as project. Feel free to use the web UI or use *tower-cli* as user *root* like shown below.

----
[root@control ~]# tower-cli project create -n "Structured Content Repository" \
                    --organization Default \
                    --scm-type git \
                    --scm-url http://control.example.com/gitea/git/structured-content.git \
                    --scm-clean 1 \
                    --scm-update-on-launch 1 \
                    --scm-credential "Gitea Credentials"
----

Now you've created the Project in Tower. Earlier on the commandline you've setup a staged environment by creating and using two different inventory files. But how can we get the same setup in Tower? We use another way to define Inventories! It is possible to use inventory files provided in a SCM repository as an inventory source. This way we can use the inventory files we keep in Gitea.

In your Tower web UI, open the *RESOURCES->Inventory* view. Then click the image:green_plus.png[20,20] button and choose to create a new *Inventory*. In the next view:

* *NAME:* Structured Content Inventory
* Click *SAVE*
* Click the button *SOURCES* which is now active at the top
* Click the image:green_plus.png[20,20] button
* *NAME:* Production
* *SOURCE:* Pick *Sourced from a Project*
* Click on *Choose an inventory file*
* *PROJECT:* Structured Content Repository 
* In the *INVENTORY FILE* drop down menu, pick *production*
* Click the green *SAVE* button

And now for the staging inventory:

* Down below in the view, click the image:green_plus.png[20,20] button again
* In the next view, add as *NAME:* Staging
* *SOURCE:* Pick *Sourced from a Project*
* Click on *Choose an inventory file*
* *PROJECT:* Structured Content Repository 
* In the *INVENTORY FILE* drop down menu, pick *staging*
* Click the green *SAVE* button
* In the screen below, click the sync button for both sources once so that the cloud icon on the left site next to the name of each inventory turns green.

To make sure that the project based inventory worked, click on the *HOSTS* button of the Inventory and make sure the two hosts are listed and tagged with the respective stages as *RELATED GROUPS*.

Now create a template to execute the `site.yml` against both stages at the same time.

TIP: Please note that in a real world use case you might want to have different templates to address the different stages separatly.

----
[root@control ~]# tower-cli job_template create -n "Structured Content Execution" \
                    --job-type run -i "Structured Content Inventory" \
                    --project "Structured Content Repository" \
                    --playbook "site.yml" \
                    --credential "Example Credentials" \
                    --become-enabled 1
----

Now in the Tower web UI go to *RESOURCES->Templates*, launch the playbook and watch the results.

=== Adding External Roles

So far we have only worked with content inside a single repository. While this drastically reduces complexity already, the largest benefit is in sharing roles among multiple teams or departments and keeping them in a central place. In this section we will show how to reference shared roles in your code and execute them together on your behalf.

In enterprise environments it is common to share roles via internal git repositories, often one git repository per role. If a role might be interesting and re-used by the world wide Ansible community, they can be shared on our central platform link:https://galaxy.ansible.com/[Ansible Galaxy]. The advantage of Ansible Galaxy is that it features basic automatic testing and community ratings to give the interested users an idea of the quality and reusability of a role.

To use external roles in a project, they need to be referenced in a file called link:https://docs.ansible.com/ansible/latest/reference_appendices/galaxy.html#installing-multiple-roles-from-a-file[`roles/requirements.yml`], for example like this:

----
# Import directly from Galaxy
- src: geerlingguy.nginx
# Import from a local Git repository
- src: http://control.example.com/gitea/git/external-role.git
  version: master
  name: external-role_locally
----

The `requirements.yml` needs to be read - either on the command line by invoking `ansible-galaxy`, or automatically by Ansible Tower during project check outs. In both cases the file is read, and the roles are checked out and stored locally, and the roles can be called in playbooks. The advantage of Tower here is that it takes care of all that - including authorization to the Git repo, finding a proper place to store the role, updating it when needed and so on. 

In this example, we will include a role which ships a simple `index.html` file as template and reloads the apache web server. The role is already shared in Gitea at *\http://control.example.com/gitea/git/shared-apache-role*.

To include it with the existing structured content, first we have to create a file called `roles/requirements.yml` and reference the role there:

WARNING: Make sure you work as user *ansible*

----
[ansible@control structured-content]$ cat roles/requirements.yml 
- src: http://control.example.com/gitea/git/shared-apache-role.git
  scm: git
  version: master
----

TIP: In a production environment you may want to change the version to a fixed version or tag, to make sure that only tested and verified code is checked out and used. But this strongly depends on how you develop your code and which branching model you use.

Here we add the source for the role and identify the type of source control.

Next, we reference the role itself in our playbook. Change the *site.yml* Playbook to look like this:

----
[ansible@control structured-content]$ cat site.yml 
---
- name: Execute apache and security roles
  hosts: all

  roles:
    - { role: apache}
    - { role: security } 
    - { role: shared-apache-role }
----

Because Tower uses the Gitea repo, you've to add, commit and push the changes:

----
[ansible@control structured-content]$ git add site.yml roles/
[ansible@control structured-content]$ git commit -m "Add roles/requirements.yml referencing shared role"
[ansible@control structured-content]$ git push
----

=== Launch in Tower

Just in case, make sure to update the Project in Tower: in the menu at *RESOURCES*, pick *Projects*, and click on the sync button next to *Structured Content Repository*.

Afterwards, go to *RESOURCES->Templates* and launch the *Structured Content Execution* job template. As you will see in the job output, the external role is called just the way the other roles are called:

----
TASK [shared-apache-role : deploy content] *************************************
changed: [host2.example.com]
changed: [host1.example.com]
----

And you are done! This was quite something to follow through, so let's review:

* You successfully integrated a shared role provided from a central source into your automation code. 
* This way, you can limit your automation code to things really relevant and individual to the task and your environment, while everything generic is consumed from a shared resource.

== OPTIONAL: Discovering the Tower API

You have used the Tower API a couple of times in this lab already. In this chapter we'll describe two ways to discover the Tower API if you need to dive in deeper. While the https://docs.ansible.com/ansible-tower/latest/html/towerapi/index.html[principles of the Tower API] are documented and there is an https://docs.ansible.com/ansible-tower/latest/html/towerapi/api_ref.html#/[API reference guide], it's often more efficient to just browse and discover the API.

=== Browsing and Using the Tower API interactively

The Tower API is browsable, which means you can just click your way through it:

. Go to the Tower UI in your browser and make sure you're logged in as admin.
. Replace the end of the URL with `/api` e.g. `\https://tower2-<GUID>.rhpds.opentlc.com/api`
. You're now in the API, notice that there are two versions. v1 will be retired soon so go to v2.
. While in `/api/v2`:
** you see a list of clickable object types
** on the right upper side, there is a button *OPTIONS* which tells you what you can do with the current object in terms of API.
** next to it there is a *GET* button which allows you to choose between getting the (raw or not) JSON output or the API format, which you're currently admiring by default.
. Click on the `/api/v2/users/` link and discover some more features:
** There is a list of all objects of the given type
** Each individual object can be reached using the `url` field ("url": "/api/v2/users/1/",)
** Most objects have a `related` field, which allows you to jump from object to object
** At the bottom of the page, there is a new field which allows you to _post_ a new object, so let's do this and create a new user name John Smith (user name doesn't matter)

+++ <details><summary> +++
*>> _Click here for the solution_ <<*
+++ </summary><div> +++

The JSON should roughly look like this:

----
{
    "username": "jsmith",
    "first_name": "John",
    "last_name": "Smith",
    "email": "jsmith@example.com",
    "is_superuser": false,
    "is_system_auditor": false,
    "password": "redhat"
}
----

and the result should be a 201 telling you about your success. You can log-in with the password and see that you see... nothing, because you have no rights. 

+++ </div></details> +++

Now log in again as admin and go back to the list of users: *https://tower2-<GUID>.rhpds.opentlc.com/api/v2/users/*

* Click on the *url* field of your new friend John Smith and notice a few more things:
** There is a red *DELETE* button at the top right level. Guess for what?
** At the bottom of the page, the dialog shows *PUT* and *PATCH* buttons.

So why not patch the user to be named "Johnny" instead of "John"?

+++ <details><summary> +++
*>> _Click here for the solution_ <<*
+++ </summary><div> +++

Add this to the *CONTENT* field:

----
{
    "first_name": "Johnny"
}
----
 
And press the *PATCH* button.

+++ </div></details> +++

Now try to *PUT* *last_name* "Smithy" using the same approach. What happens?
 
+++ <details><summary> +++
*>> _Click here for the solution_ <<*
+++ </summary><div> +++

Enter this into the *CONTENT* field and press *PUT*:

----
{
    "last_name": "Smithy"
}
----

This will fail. In the case of *PUT* you need to enter all mandatory fields, even if you don't want to modify them:

----
{
    "username": "jsmith",
    "last_name": "Smithy"
}
----
+++ </div></details> +++

When you're done press the red *DELETE* button and remove Johnny Smithy.

=== Using tower-cli to Learn the API

The Web UI is nice but we love the command line, right? To learn about API calls `tower-cli` comes to the rescue. For the next steps bring up an SSH session and make sure you are user root on *control.example.com*. 

Let's start simple and try to get the version of Tower installed:

----
[root@control ~]# tower-cli version --verbose
Tower CLI 3.3.0
API v2
GET https://tower2.example.com/api/v2/config/
Params: {}

Ansible Tower 3.4.1
Ansible 2.7.5
----

You see that with the `--verbose` option, tower-cli tells us which API calls it's making, what *parameters* it's sending with *GET* requests and what *data* is needed for *POST* actions. 

In this simple case you can simply take the call and run it with e.g. *curl*:

----
[root@control ~]# curl -k -H 'Content-Type: application/json' --user admin:r3dh4t1! \
	--data '{}' \
	-X GET https://tower1.example.com/api/v2/config/ | jq
----

TIP: `jq` is optional but useful for us humans to understand the output without getting dizzy... in this case it comes from the EPEL repo. If you don't have `jq` appending `| python -m json.tool` to the command is better then nothing.

==== Practice, Practice...

Using `tower-cli` to learn about the API call and executing it via curl e.g. in scripts is really useful so let's practice a bit. What about creating a new user, say Albert Miller?

TIP: Consider that the parameters shown by tower-cli are in Python format (single quotes and the unicode `u`) but we need to send data in JSON format (double quotes).

First create the user with tower-cli, then delete it again. Use `--verbose` to get the API invocation. 

----
[root@control ~]# tower-cli user create --username amiller --email amiller@example.com --password redhat --verbose

*** DETAILS: Checking for an existing record. *********************************
GET https://tower2.example.com/api/v2/users/
Params: {'username': u'amiller'}

*** DETAILS: Writing the record. **********************************************
POST https://tower2.example.com/api/v2/users/
Data: {'username': u'amiller', 'password': u'redhat', 'email': u'amiller@example.com'}
----

----
[root@control ~]# tower-cli user delete --username amiller --verbose

*** DETAILS: Getting the record. **********************************************
GET https://tower2.example.com/api/v2/users/
Params: {'username': u'amiller'}

DELETE /users/3/
DELETE https://tower2.example.com/api/v2/users/3/
----

Now we'll do the same using *curl* with the API endpoints, parameters and data we have learned from `tower-cli`:

WARNING: The "Getting the record" is (sadly) a bit misleading...  you need to add `?username=amiller` to filter on the username:

Check if the user exists:

----
[root@control ~]# curl -k -H 'Content-Type: application/json' --user admin:r3dh4t1! \
	-X GET https://tower1.example.com/api/v2/users/?username=amiller
----

Once you've found out that the user doesn't exist by *count:0* in the reply, you can create it:

----
[root@control ~]# curl -k -H 'Content-Type: application/json' --user admin:r3dh4t1! \
	--data '{"username": "amiller", "password": "redhat", "email": "amiller@example.com"}' \
	-X POST https://tower1.example.com/api/v2/users/?username=amiller
----

Run the `curl` command from above again to check the user now exists, it should return *count:1* and the user's data.

Note the ID of the user and then delete it:

WARNING: Replace *<ID>*

----
[root@control ~]# curl -k -H 'Content-Type: application/json' --user admin:r3dh4t1! \
	-X DELETE https://tower1.example.com/api/v2/users/<ID>/ # <1>
----
<1> don't forget the slash at the end of the URL, favorite error!

+++ </div></details> +++

== Appendix

=== Setup Considerations

Here are a number of things to consider when planning a clustered Tower deployment:

* The PostgreSQL database is a central component of the cluster. Ansible Tower is not taking care of availabilty, redundancy or replication of the database, this has to be configured "outside" of Tower.
* The number of instances in a cluster should always be an *odd number* and a minimum number of three is strongly recommended with a maximum of 20.
* RabbitMQ is a core component, so a lot of the requirements are dictated by it. Like e.g. the odd node count for quorum...
* Typical cluster considerations apply: All nodes need to be able to reliably connect to each other, stable address/hostname resolution, geographically co-located with reliable low-latency connections between instances.
* Remember there is no concept of primary/secondary instance, all systems are primary.

==== Installing an Ansible Tower Cluster

For initial configuration of a Tower cluster and for adding new instances the default Ansible installer is used, but the inventory file needs to be extended. Some important basic concepts:

* There has to be at least an inventory group named `tower`. We'll cover instance groups later, but keep in mind the nodes in this group are responsible for housekeeping tasks like where to launch jobs or to process playbook events.
* If all Tower instances in this group fail, jobs might not run and playbook events might not get written. So make sure there are enough instances in this group.
* The database can be installed and configured by the installer by adding the host to the `database` group. If the database host is provisioned separately, leave the group empty.

==== The Installer Inventory File

In this lab a three node Ansible Tower cluster is provided ready to go as installing it would eat too much of your lab time. It's pretty straight forward anyway. The inventory file here is just for giving you an idea what you are using here and for reference.

TIP: Keep in mind when working with clustered Ansible Tower that the database will not be clustered or replicated by the installer. This is something you have to take care of yourself.

----
[tower]
tower1.example.com
tower2.example.com
tower3.example.com

[database]
towerdb.example.com

[all:vars]
ansible_become=true

admin_password='r3dh4t1!'

pg_host='towerdb.example.com'
pg_port='5432'

pg_database='tower'
pg_username='tower'
pg_password='r3dh4t1!'

rabbitmq_port=5672
rabbitmq_vhost=tower
rabbitmq_username=tower
rabbitmq_password='r3dh4t1!'
rabbitmq_cookie=rabbitmqcookie
----

WARNING: In this lab this has been taken care of, but remember all instances have to able to resolve all hostnames and to reach each other!

